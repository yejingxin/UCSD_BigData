{
 "metadata": {
  "name": "",
  "signature": "sha256:97744abc7eedbb111411bc1a6ecace2353bdab873c3b8feaeba2a46fe9ca28ac"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Mining Data Streams ##\n",
      "This notebook is based on [chapter 4](http://infolab.stanford.edu/~ullman/mmds/ch4.pdf) of the book [Mining of Massive Datasets](http://infolab.stanford.edu/~ullman/mmds.html#latest) by Anand Rajarman, Jure Leskovec and Jeffrey Ullman."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "The problem with using sampling to find the fraction of doubles"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Section 4.2.1 presents a situation where simple sampling gives incorrect results. Consider a stream consisting of many different items. \n",
      "$s$ of the items occur once (singles) and $d$ of the items occur twice (doubles). our goal is to estimate the fraction of the items that occur twice, i.e. $\\frac{d}{d+s}$\n",
      "\n",
      "Consider the strategy of taking a sample of $N$ data points from the sequence of length $s+2*d$ and counting the number of doubles in the sample.\n",
      "\n",
      "As is shown in the book, this method has the problem of severly under-sampling the doubles. The reason is that if the sample is much smaller than the size of the sequence the probability  of getting only one element in a double is much higher than the probability of getting both elements. \n",
      "\n",
      "The code below demonstrates this effect for the values of $d,s,N$ of your choosing."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import random as r\n",
      "s=100000   # number of singles\n",
      "d=100000   # number of doubles\n",
      "N=3000    # size of sample\n",
      "ids=permutation(range(s+d))   # the items are random numbers in the range 0 to s+d-1\n",
      "singles=[i for i in ids[:s]]\n",
      "doubles=[[i,i] for i in ids[s:]]\n",
      "doubles=list(concatenate(doubles))\n",
      "L=singles+doubles\n",
      "L=permutation(L)  # Randomly permute the sequence so that sampling can be done by taking the first N elements\n",
      "Sample=L[:N]\n",
      "Uniques=np.unique(Sample)\n",
      "d_est=float(len(Sample)-len(Uniques))\n",
      "print 'the number of doubles in the sample is ',d_est\n",
      "print 'which gives us an estimate that %8.7f of the items are doubles' % (d_est/(N-d_est))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "the number of doubles in the sample is  8.0\n",
        "which gives us an estimate that 0.0026738 of the items are doubles\n"
       ]
      }
     ],
     "prompt_number": 364
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "A simple but wasteful solution"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In section 4.2.2 the book describes a simple solution to the problem. Suppose we know all of the elements that can appear in the sequence in advance. In the example above, the items are numbers in the range [0,s+d-1]. We can decide ahead of time which of the items to count and which to ignore. In this way we can guarantee an unbiased sample. To decide which items to include and which to ignore we create a boolean vector whose length is $s+d$ and in which each item is chosen to be \"True\" with probability $N/s+d$. Note that the size of the selected set of items is a random variable whose expected value is $N$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "selector=random.rand(s+d) < (N+0.0)/(s+d+0.0)  # selector is a vector that identifies which items will be included in the sample\n",
      "print 'from ',len(selector),' elements,',sum(selector),'were selected'\n",
      "Sample=[item for item in L if selector[item]]\n",
      "Uniques=np.unique(Sample)\n",
      "d_est=float(len(Sample)-len(Uniques))\n",
      "print 'The sample size is',len(Sample)\n",
      "print 'the number of doubles in the sample is ',d_est\n",
      "print 'which gives us an estimate that %8.7f of the items are doubles' % (d_est/(len(Sample)-d_est))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "from  200000  elements, 3059 were selected\n",
        "The sample size is"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4598\n",
        "the number of doubles in the sample is  1539.0\n",
        "which gives us an estimate that 0.5031056 of the items are doubles\n"
       ]
      }
     ],
     "prompt_number": 374
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The solution given above gives an unbiased estimate. However, it is usually infeasable, for at least two reasons:\n",
      "\n",
      "1. The list of possible items might be extremely large, consider, for example, all possible URLs.\n",
      "2. The list of items might not be known beforehand.\n",
      "\n",
      "### Hashing ###\n",
      "By using **Hashing** we can emulate the previous solution without incurring the high cost of a \"selector\" list.\n",
      "\n",
      "A Hash function is a function that that maps a large set $X$ (say all possible URLs) to a small set $Y$ (say the integers $1,\\cdots,N$) and that has the following two properties:\n",
      "\n",
      "1. For any $x \\in X$ and any $1\\leq i\\leq N$ the probability that $H(x)=i$ is $1/N$ independently of **anything** else. In particular, independently of the value of $H(x')$ for any $x' \\neq x, x' \\in X$.\n",
      "2. Separate Computations of $H(x)$ (for the same value of $x$) yield the same value.\n",
      "\n",
      "Satisfying condition 1 without condition 2 is easy: just draw a number from the uniform distribution over $1,\\ldots,N$. The problem with that solution is that property 2 does not hold. In other words, when we compute $H(x)$ a second time, we are likely to get a different number.\n",
      "\n",
      "In fact, if you think about it, if there is only one hash function $H$, then the whole notion of $H(x)$ being a random variable is bogus. It is simply a constant and saying that two constants (for two different values $x_1 \\neq x_2$) are independent makes no sense.\n",
      "\n",
      "Defining Hash functions in a way that does make sense requires that we think of a **set** of hash functions $H_1,H_2,\\ldots,H_N$, and that we assume that at the beginning of our algorithm we pick at random one or more of these functions and then use them throughout the algorithm.\n",
      "Now we can make sense of the statement\n",
      "\n",
      "> For any $x \\in X$ and any $1\\leq i\\leq N$ the probability that $H_j(x)=i$ is $1/N$ independently of **anything** else.\"\n",
      "\n",
      "The statement is supposed to hold true with respect to the random choice of the index $j$.\n",
      "\n",
      "A trivial way to achieve this is to include in the set of functions **all** functions from $X$ to $Y$. However the number of bits that the index $i$ would need to have in this case is\n",
      "$\\log_2 N^{|X|} = |X| \\log_2 N$, which is to say that the index defines, for each element of $X$, the element in $Y$ to which it is mapped. This amount to keeping the table the way we did in the previous solution.\n",
      "\n",
      "So the question becomes - are there **small** sets of hash functions that have property 1. As it turns out the answer is a qualified yes. As it turns out, the construction of good families of hash functions is closely related to the construction of *Pseudo Random Number Generators*"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Pseudo-Random Number Generators ###\n",
      "A pseudo random number generator (PRNG) is a computer program that is initialized by recieving a **seed**. The seed is used to set the initial **state** $S_0$ of the PRNG.\n",
      "\n",
      "Each subsequent call to the PRNG results in two operations:\n",
      "\n",
      "1. An output is generated $O_t=G(S_{t})$\n",
      "1. The state is updated using a function $S_{t+1}=F(S_t)$.\n",
      "\n",
      "The output of the PRNG \"looks\" as if it was random. More precisely, given $S_t$ one cannot infer anything about $S_{t-1},S_{t-2},\\ldots,..,S_0$. This limitation is **computational**, it is not hard to show that given unlimited computational resources, one can reverse any pseudo-random number generator. The theory of PRNG is a mathematically deep area and is intimately linked to computational complexity. You can read more about it [here](http://en.wikipedia.org/wiki/Pseudorandom_generator)\n",
      "\n",
      "In practice, there is a range of PRNG functions. The simplest and easiest to calculate have relatively weak guarantees (for example, that the number of steps it takes to get back to the initial state), to ones that have strong cryptographic guarantees on how difficult it is to reverse them. The last usually require more computational resources.\n",
      "\n",
      "Very secure hash functions are central to cryptography. Such hash functions are implemented in the python library [hashlib](https://docs.python.org/2.7/library/hashlib.html). This is probably an over-kill for our purposes of data analysis.\n",
      "\n",
      "A basic hash function is built into python. [hash](https://docs.python.org/2/library/functions.html#hash) does not come with **any** guarantees on it's statistical properties. It might be too weak for our purposes.\n",
      "\n",
      "For our purposes here I am defining a _hash class_ that is based on the _random_ module (here imported as _r_)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Defining a random hash function class"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%%writefile Hash.py\n",
      "import random as r\n",
      "class Hash:\n",
      "    \"\"\" This class defines a random hash function. When an object from this class is initialized, \n",
      "        it's seed is chosen at random and fixed. When called with a any hashable value, the seed is appnded to the value\n",
      "        and then a random number is generated using the combination of seed and value as it's seed\"\"\"\n",
      "    def __init__(self,range=2):\n",
      "        self.range=range\n",
      "        r.seed()\n",
      "        self.seed=int(1000000*r.random())\n",
      "\n",
      "    # An implementation using random.randint\n",
      "    def map(self,x,range=None):\n",
      "        if range==None: range=self.range\n",
      "        r.seed((self.seed,x))\n",
      "        return r.randint(0,range-1)    \n",
      "\n",
      "    # An implementation using hash\n",
      "    def map1(self,x,range=None):\n",
      "        if range==None: range=self.range\n",
      "        return hash((x,self.seed))%range\n",
      "        #r.seed((self.seed,x))\n",
      "        #return r.randint(0,range-1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 393
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Testing that two different functions are not correlated ####\n",
      "Lets test to see that the binary sequences that are generated by two different has functions are not correlated. This is just a sanity test, to see that the correlation is as low as expected from pseudo-random sequences."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "H1=Hash()\n",
      "H2=Hash()\n",
      "n=1000\n",
      "S1=np.zeros(n)\n",
      "S2=np.zeros(n)\n",
      "for i in range(n):\n",
      "    S1[i]=2*H1.map(i)-1\n",
      "    S2[i]=2*H2.map(i)-1\n",
      "#print S1\n",
      "#print S2\n",
      "print mean(S1),mean(S2),mean(multiply(S1,S2)),mean(multiply(S1,S1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.004 -0.022 0.01 1.0\n"
       ]
      }
     ],
     "prompt_number": 398
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Checking that maping the same item using two different functions gives the same result.\n",
      "H1.map('Yoav',range=1000),H2.map('Yoav',range=1000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 110,
       "text": [
        "(600, 567)"
       ]
      }
     ],
     "prompt_number": 110
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "A memory efficient solution using Hashing"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "H=Hash(range=(d+s)/N)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 379
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "selected=sum([H.map(i)==0 for i in range(s+d)])\n",
      "print 'selected %d out of %d items'%(selected,s+d)\n",
      "Sample=[item for item in L if H.map(item)==0]\n",
      "Uniques=np.unique(Sample)\n",
      "d_est=float(len(Sample)-len(Uniques))\n",
      "print 'The sample size is',len(Sample)\n",
      "print 'the number of doubles in the sample is ',d_est\n",
      "print 'which gives us an estimate that %8.7f of the items are doubles' % (d_est/(len(Sample)-d_est))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "selected 3029 out of 200000 items\n",
        "The sample size is"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4507\n",
        "the number of doubles in the sample is  1478.0\n",
        "which gives us an estimate that 0.4879498 of the items are doubles\n"
       ]
      }
     ],
     "prompt_number": 399
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that this method works without change for any size set of possible items. For example, an item can be a URL or even a whole document.\n",
      "\n",
      "This is the first use we see for hashing in data analysis. In the next notebook we will explore a few others."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hash('yoav')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 386,
       "text": [
        "4640194801341207605"
       ]
      }
     ],
     "prompt_number": 386
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}