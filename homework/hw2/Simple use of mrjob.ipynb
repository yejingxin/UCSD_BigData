{
 "metadata": {
  "name": "",
  "signature": "sha256:c6989f835b1a623fedf0250cf2ee5de2813b03661459bc15206799d921a71e6c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##mrjob##\n",
      "\n",
      "__mrjob__ is a software package developed by the restaurant recommendation company _Yelp_. \n",
      "It's goal is to simplify the deployment of map-reduce jobs based on streaming and python onto different \n",
      "frameworks such as Hadoop on a private cluster or hadoop on AWS (called EMR).\n",
      "\n",
      "* You can read more about mrjob here: https://pythonhosted.org/mrjob/index.html  \n",
      "* and you can clone it from github here: https://github.com/yelp/mrjob\n",
      "\n",
      "In this notebook we run a simple word-count example, add to it some logging commands, and look at two modes of running the job."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#root_dir = '/home/ubuntu/packages/mrjob'\n",
      "root_dir = '~/UCSD_BigData/notebooks/mrjob'\n",
      "examples_dir=root_dir#+'/examples/'\n",
      "!ls $examples_dir\n",
      "from mrjob.job import MRJob"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "counts\t\t\tmr_word_freq_counters.py  README.rst\r\n",
        "Jobs_and_runners.ipynb\tmr_word_freq_count.py\t  Simple use of mrjob.ipynb\r\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filename=examples_dir+'/mr_word_freq_count.py'\n",
      "print filename\n",
      "!ls $filaname\n",
      "# load example code from mr jobs as a starting point\n",
      "%load  $filename"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "~/UCSD_BigData/notebooks/mrjob/mr_word_freq_count.py\n",
        "counts\t\t\tmr_word_freq_counters.py  README.rst\r\n",
        "Jobs_and_runners.ipynb\tmr_word_freq_count.py\t  Simple use of mrjob.ipynb\r\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!/usr/bin/python\n",
      "# Copyright 2009-2010 Yelp\n",
      "#\n",
      "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
      "# you may not use this file except in compliance with the License.\n",
      "# You may obtain a copy of the License at\n",
      "#\n",
      "# http://www.apache.org/licenses/LICENSE-2.0\n",
      "#\n",
      "# Unless required by applicable law or agreed to in writing, software\n",
      "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
      "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
      "# See the License for the specific language governing permissions and\n",
      "# limitations under the License.\n",
      "\"\"\"The classic MapReduce job: count the frequency of words.\n",
      "\"\"\"\n",
      "from mrjob.job import MRJob\n",
      "import re\n",
      "from sys import stderr\n",
      "\n",
      "WORD_RE = re.compile(r\"[\\w']+\")\n",
      "\n",
      "#logfile=open('log','w')\n",
      "logfile=stderr\n",
      "\n",
      "class MRWordFreqCount(MRJob):\n",
      "\n",
      "    def mapper(self, _, line):\n",
      "        for word in WORD_RE.findall(line):\n",
      "            logfile.write('mapper '+word.lower()+'\\n')\n",
      "            yield (word.lower(), 1)\n",
      "\n",
      "    def combiner(self, word, counts):\n",
      "        #yield (word, sum(counts))\n",
      "        l_counts=[c for c in counts]  # extract list from iterator\n",
      "        S=sum(l_counts)\n",
      "        logfile.write('combiner '+word+' ['+','.join([str(c) for c in l_counts])+']='+str(S)+'\\n')\n",
      "        yield (word, S)\n",
      "\n",
      "    def reducer(self, word, counts):\n",
      "        #yield (word, sum(counts))\n",
      "        l_counts=[c for c in counts]  # extract list from iterator\n",
      "        S=sum(l_counts)\n",
      "        logfile.write('reducer '+word+' ['+','.join([str(c) for c in l_counts])+']='+str(S)+'\\n')\n",
      "        yield (word, S)\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    MRWordFreqCount.run()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!/usr/bin/python\n",
      "# Copyright 2009-2010 Yelp\n",
      "#\n",
      "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
      "# you may not use this file except in compliance with the License.\n",
      "# You may obtain a copy of the License at\n",
      "#\n",
      "# http://www.apache.org/licenses/LICENSE-2.0\n",
      "#\n",
      "# Unless required by applicable law or agreed to in writing, software\n",
      "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
      "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
      "# See the License for the specific language governing permissions and\n",
      "# limitations under the License.\n",
      "\"\"\"The classic MapReduce job: count the frequency of words.\n",
      "\"\"\"\n",
      "from mrjob.job import MRJob\n",
      "import re\n",
      "\n",
      "WORD_RE = re.compile(r\"[\\w']+\")\n",
      "\n",
      "\n",
      "class MRWordFreqCount(MRJob):\n",
      "\n",
      "    def mapper(self, _, line):\n",
      "        for word in WORD_RE.findall(line):\n",
      "            yield (word.lower(), 1)\n",
      "\n",
      "    def combiner(self, word, counts):\n",
      "        yield (word, sum(counts))\n",
      "\n",
      "    def reducer(self, word, counts):\n",
      "        yield (word, sum(counts))\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    MRWordFreqCount.run()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%writefile mr_word_freq_count.py\n",
      "#!/usr/bin/python\n",
      "# Copyright 2009-2010 Yelp\n",
      "#\n",
      "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
      "# you may not use this file except in compliance with the License.\n",
      "# You may obtain a copy of the License at\n",
      "#\n",
      "# http://www.apache.org/licenses/LICENSE-2.0\n",
      "#\n",
      "# Unless required by applicable law or agreed to in writing, software\n",
      "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
      "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
      "# See the License for the specific language governing permissions and\n",
      "# limitations under the License.\n",
      "\"\"\"The classic MapReduce job: count the frequency of words.\n",
      "\"\"\"\n",
      "from mrjob.job import MRJob\n",
      "import re\n",
      "from sys import stderr\n",
      "\n",
      "WORD_RE = re.compile(r\"[\\w']+\")\n",
      "\n",
      "#logfile=open('log','w')\n",
      "logfile=stderr\n",
      "\n",
      "class MRWordFreqCount(MRJob):\n",
      "\n",
      "    def mapper(self, _, line):\n",
      "        logfile.write('%s\\n' % WORD_RE.findall(line))\n",
      "        for word in WORD_RE.findall(line):\n",
      "            logfile.write('mapper '+word.lower()+'\\n')\n",
      "            yield (word.lower(), 1)\n",
      "\n",
      "    def combiner(self, word, counts):\n",
      "        #yield (word, sum(counts))\n",
      "        l_counts=[c for c in counts]  # extract list from iterator\n",
      "        S=sum(l_counts),\n",
      "        logfile.write('combiner '+word+' ['+','.join([str(c) for c in l_counts])+']='+str(S)+'\\n')\n",
      "        yield (word, S)\n",
      "\n",
      "    def reducer(self, word, counts):\n",
      "        #yield (word, sum(counts))\n",
      "        l_counts=[c for c in counts]  # extract list from iterator\n",
      "        S=sum(l_counts)\n",
      "        logfile.write('reducer '+word+' ['+','.join([str(c) for c in l_counts])+']='+str(S)+'\\n')\n",
      "        yield (word, S)\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    MRWordFreqCount.run()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting mr_word_freq_count.py\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%writefile mr_word_freq_count_test.py\n",
      "#!/usr/bin/python\n",
      "# Copyright 2009-2010 Yelp\n",
      "#\n",
      "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
      "# you may not use this file except in compliance with the License.\n",
      "# You may obtain a copy of the License at\n",
      "#\n",
      "# http://www.apache.org/licenses/LICENSE-2.0\n",
      "#\n",
      "# Unless required by applicable law or agreed to in writing, software\n",
      "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
      "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
      "# See the License for the specific language governing permissions and\n",
      "# limitations under the License.\n",
      "\"\"\"The classic MapReduce job: count the frequency of words.\n",
      "\"\"\"\n",
      "from mrjob.job import MRJob\n",
      "import re\n",
      "from sys import stderr\n",
      "\n",
      "WORD_RE = re.compile(r\"[\\w']+\")\n",
      "\n",
      "#logfile=open('log','w')\n",
      "logfile=stderr\n",
      "\n",
      "class MRWordFreqCount(MRJob):\n",
      "\n",
      "    def mapper(self, _, line):\n",
      "        logfile.write('%s\\n' % WORD_RE.findall(line))\n",
      "        for word in WORD_RE.findall(line):\n",
      "            logfile.write('mapper '+word.lower()+'\\n')\n",
      "            yield ((word.lower(),word.lower()), (1,2))\n",
      "\n",
      "    def combiner(self, word, counts):\n",
      "        #yield (word, sum(counts))\n",
      "        l_counts=[c for c in counts]  # extract list from iterator\n",
      "        #S=sum(l_counts),\n",
      "        S1=0\n",
      "        S2=0\n",
      "        for c in l_counts:\n",
      "            S1 = S1 + c[0]\n",
      "            S2 = S2 + c[1]\n",
      "        logfile.write('combiner '+word[0]+word[1]+' ['+','.join([str(c[0]) for c in l_counts])+','.join([str(c[1]) for c in l_counts])+']='+str(S1)+','+str(S2)+'\\n')\n",
      "        yield (word, (S1,S2))\n",
      "\n",
      "    def reducer(self, word, counts):\n",
      "        #yield (word, sum(counts))\n",
      "        l_counts=[c for c in counts]  # extract list from iterator\n",
      "        #S=sum(l_counts),\n",
      "        S1=0\n",
      "        S2=0\n",
      "        for c in l_counts:\n",
      "            S1 = S1 + c[0]\n",
      "            S2 = S2 + c[1]\n",
      "        logfile.write('reducer '+word[0]+word[1]+' ['+','.join([str(c[0]) for c in l_counts])+','.join([str(c[1]) for c in l_counts])+']='+str(S1)+','+str(S2)+'\\n')\n",
      "        yield (word, (S1,S2))\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    MRWordFreqCount.run()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting mr_word_freq_count_test.py\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python mr_word_freq_count_test.py ./mr_word_freq_count_test.py > counts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "using configs in /home/ubuntu/.mrjob.conf\r\n",
        "creating tmp directory /tmp/mr_word_freq_count_test.ubuntu.20140520.191132.787986\r\n",
        "writing to /tmp/mr_word_freq_count_test.ubuntu.20140520.191132.787986/step-0-mapper_part-00000\r\n",
        "['usr', 'bin', 'python']\r\n",
        "mapper usr\r\n",
        "mapper bin\r\n",
        "mapper python\r\n",
        "['Copyright', '2009', '2010', 'Yelp']\r\n",
        "mapper copyright\r\n",
        "mapper 2009\r\n",
        "mapper 2010\r\n",
        "mapper yelp\r\n",
        "[]\r\n",
        "['Licensed', 'under', 'the', 'Apache', 'License', 'Version', '2', '0', 'the', 'License']\r\n",
        "mapper licensed\r\n",
        "mapper under\r\n",
        "mapper the\r\n",
        "mapper apache\r\n",
        "mapper license\r\n",
        "mapper version\r\n",
        "mapper 2\r\n",
        "mapper 0\r\n",
        "mapper the\r\n",
        "mapper license\r\n",
        "['you', 'may', 'not', 'use', 'this', 'file', 'except', 'in', 'compliance', 'with', 'the', 'License']\r\n",
        "mapper you\r\n",
        "mapper may\r\n",
        "mapper not\r\n",
        "mapper use\r\n",
        "mapper this\r\n",
        "mapper file\r\n",
        "mapper except\r\n",
        "mapper in\r\n",
        "mapper compliance\r\n",
        "mapper with\r\n",
        "mapper the\r\n",
        "mapper license\r\n",
        "['You', 'may', 'obtain', 'a', 'copy', 'of', 'the', 'License', 'at']\r\n",
        "mapper you\r\n",
        "mapper may\r\n",
        "mapper obtain\r\n",
        "mapper a\r\n",
        "mapper copy\r\n",
        "mapper of\r\n",
        "mapper the\r\n",
        "mapper license\r\n",
        "mapper at\r\n",
        "[]\r\n",
        "['http', 'www', 'apache', 'org', 'licenses', 'LICENSE', '2', '0']\r\n",
        "mapper http\r\n",
        "mapper www\r\n",
        "mapper apache\r\n",
        "mapper org\r\n",
        "mapper licenses\r\n",
        "mapper license\r\n",
        "mapper 2\r\n",
        "mapper 0\r\n",
        "[]\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['Unless', 'required', 'by', 'applicable', 'law', 'or', 'agreed', 'to', 'in', 'writing', 'software']\r\n",
        "mapper unless\r\n",
        "mapper required\r\n",
        "mapper by\r\n",
        "mapper applicable\r\n",
        "mapper law\r\n",
        "mapper or\r\n",
        "mapper agreed\r\n",
        "mapper to\r\n",
        "mapper in\r\n",
        "mapper writing\r\n",
        "mapper software\r\n",
        "['distributed', 'under', 'the', 'License', 'is', 'distributed', 'on', 'an', 'AS', 'IS', 'BASIS']\r\n",
        "mapper distributed\r\n",
        "mapper under\r\n",
        "mapper the\r\n",
        "mapper license\r\n",
        "mapper is\r\n",
        "mapper distributed\r\n",
        "mapper on\r\n",
        "mapper an\r\n",
        "mapper as\r\n",
        "mapper is\r\n",
        "mapper basis\r\n",
        "['WITHOUT', 'WARRANTIES', 'OR', 'CONDITIONS', 'OF', 'ANY', 'KIND', 'either', 'express', 'or', 'implied']\r\n",
        "mapper without\r\n",
        "mapper warranties\r\n",
        "mapper or\r\n",
        "mapper conditions\r\n",
        "mapper of\r\n",
        "mapper any\r\n",
        "mapper kind\r\n",
        "mapper either\r\n",
        "mapper express\r\n",
        "mapper or\r\n",
        "mapper implied\r\n",
        "['See', 'the', 'License', 'for', 'the', 'specific', 'language', 'governing', 'permissions', 'and']\r\n",
        "mapper see\r\n",
        "mapper the\r\n",
        "mapper license\r\n",
        "mapper for\r\n",
        "mapper the\r\n",
        "mapper specific\r\n",
        "mapper language\r\n",
        "mapper governing\r\n",
        "mapper permissions\r\n",
        "mapper and\r\n",
        "['limitations', 'under', 'the', 'License']\r\n",
        "mapper limitations\r\n",
        "mapper under\r\n",
        "mapper the\r\n",
        "mapper license\r\n",
        "['The', 'classic', 'MapReduce', 'job', 'count', 'the', 'frequency', 'of', 'words']\r\n",
        "mapper the\r\n",
        "mapper classic\r\n",
        "mapper mapreduce\r\n",
        "mapper job\r\n",
        "mapper count\r\n",
        "mapper the\r\n",
        "mapper frequency\r\n",
        "mapper of\r\n",
        "mapper words\r\n",
        "[]\r\n",
        "['from', 'mrjob', 'job', 'import', 'MRJob']\r\n",
        "mapper from\r\n",
        "mapper mrjob\r\n",
        "mapper job\r\n",
        "mapper import\r\n",
        "mapper mrjob\r\n",
        "['import', 're']\r\n",
        "mapper import\r\n",
        "mapper re\r\n",
        "['from', 'sys', 'import', 'stderr']\r\n",
        "mapper from\r\n",
        "mapper sys\r\n",
        "mapper import\r\n",
        "mapper stderr\r\n",
        "[]\r\n",
        "['WORD_RE', 're', 'compile', 'r', \"w'\"]\r\n",
        "mapper word_re\r\n",
        "mapper re\r\n",
        "mapper compile\r\n",
        "mapper r\r\n",
        "mapper w'\r\n",
        "[]\r\n",
        "['logfile', 'open', \"'log'\", \"'w'\"]\r\n",
        "mapper logfile\r\n",
        "mapper open\r\n",
        "mapper 'log'\r\n",
        "mapper 'w'\r\n",
        "['logfile', 'stderr']\r\n",
        "mapper logfile\r\n",
        "mapper stderr\r\n",
        "[]\r\n",
        "['class', 'MRWordFreqCount', 'MRJob']\r\n",
        "mapper class\r\n",
        "mapper mrwordfreqcount\r\n",
        "mapper mrjob\r\n",
        "[]\r\n",
        "['def', 'mapper', 'self', '_', 'line']\r\n",
        "mapper def\r\n",
        "mapper mapper\r\n",
        "mapper self\r\n",
        "mapper _\r\n",
        "mapper line\r\n",
        "['logfile', 'write', \"'\", 's', \"n'\", 'WORD_RE', 'findall', 'line']\r\n",
        "mapper logfile\r\n",
        "mapper write\r\n",
        "mapper '\r\n",
        "mapper s\r\n",
        "mapper n'\r\n",
        "mapper word_re\r\n",
        "mapper findall\r\n",
        "mapper line\r\n",
        "['for', 'word', 'in', 'WORD_RE', 'findall', 'line']\r\n",
        "mapper for\r\n",
        "mapper word\r\n",
        "mapper in\r\n",
        "mapper word_re\r\n",
        "mapper findall\r\n",
        "mapper line\r\n",
        "['logfile', 'write', \"'mapper\", \"'\", 'word', 'lower', \"'\", \"n'\"]\r\n",
        "mapper logfile\r\n",
        "mapper write\r\n",
        "mapper 'mapper\r\n",
        "mapper '\r\n",
        "mapper word\r\n",
        "mapper lower\r\n",
        "mapper '\r\n",
        "mapper n'\r\n",
        "['yield', 'word', 'lower', 'word', 'lower', '1', '2']\r\n",
        "mapper yield\r\n",
        "mapper word\r\n",
        "mapper lower\r\n",
        "mapper word\r\n",
        "mapper lower\r\n",
        "mapper 1\r\n",
        "mapper 2\r\n",
        "[]\r\n",
        "['def', 'combiner', 'self', 'word', 'counts']\r\n",
        "mapper def\r\n",
        "mapper combiner\r\n",
        "mapper self\r\n",
        "mapper word\r\n",
        "mapper counts\r\n",
        "['yield', 'word', 'sum', 'counts']\r\n",
        "mapper yield\r\n",
        "mapper word\r\n",
        "mapper sum\r\n",
        "mapper counts\r\n",
        "['l_counts', 'c', 'for', 'c', 'in', 'counts', 'extract', 'list', 'from', 'iterator']\r\n",
        "mapper l_counts\r\n",
        "mapper c\r\n",
        "mapper for\r\n",
        "mapper c\r\n",
        "mapper in\r\n",
        "mapper counts\r\n",
        "mapper extract\r\n",
        "mapper list\r\n",
        "mapper from\r\n",
        "mapper iterator\r\n",
        "['S', 'sum', 'l_counts']\r\n",
        "mapper s\r\n",
        "mapper sum\r\n",
        "mapper l_counts\r\n",
        "['S1', '0']\r\n",
        "mapper s1\r\n",
        "mapper 0\r\n",
        "['S2', '0']\r\n",
        "mapper s2\r\n",
        "mapper 0\r\n",
        "['for', 'c', 'in', 'l_counts']\r\n",
        "mapper for\r\n",
        "mapper c\r\n",
        "mapper in\r\n",
        "mapper l_counts\r\n",
        "['S1', 'S1', 'c', '0']\r\n",
        "mapper s1\r\n",
        "mapper s1\r\n",
        "mapper c\r\n",
        "mapper 0\r\n",
        "['S2', 'S2', 'c', '1']\r\n",
        "mapper s2\r\n",
        "mapper s2\r\n",
        "mapper c\r\n",
        "mapper 1\r\n",
        "['logfile', 'write', \"'combiner\", \"'\", 'word', '0', 'word', '1', \"'\", \"'\", \"'\", \"'\", 'join', 'str', 'c', '0', 'for', 'c', 'in', 'l_counts', \"'\", \"'\", 'join', 'str', 'c', '1', 'for', 'c', 'in', 'l_counts', \"'\", \"'\", 'str', 'S1', \"'\", \"'\", 'str', 'S2', \"'\", \"n'\"]\r\n",
        "mapper logfile\r\n",
        "mapper write\r\n",
        "mapper 'combiner\r\n",
        "mapper '\r\n",
        "mapper word\r\n",
        "mapper 0\r\n",
        "mapper word\r\n",
        "mapper 1\r\n",
        "mapper '\r\n",
        "mapper '\r\n",
        "mapper '\r\n",
        "mapper '\r\n",
        "mapper join\r\n",
        "mapper str\r\n",
        "mapper c\r\n",
        "mapper 0\r\n",
        "mapper for\r\n",
        "mapper c\r\n",
        "mapper in\r\n",
        "mapper l_counts\r\n",
        "mapper '\r\n",
        "mapper '\r\n",
        "mapper join\r\n",
        "mapper str\r\n",
        "mapper c\r\n",
        "mapper 1\r\n",
        "mapper for\r\n",
        "mapper c\r\n",
        "mapper in\r\n",
        "mapper l_counts\r\n",
        "mapper '\r\n",
        "mapper '\r\n",
        "mapper str\r\n",
        "mapper s1\r\n",
        "mapper '\r\n",
        "mapper '\r\n",
        "mapper str\r\n",
        "mapper s2\r\n",
        "mapper '\r\n",
        "mapper n'\r\n",
        "['yield', 'word', 'S1', 'S2']\r\n",
        "mapper yield\r\n",
        "mapper word\r\n",
        "mapper s1\r\n",
        "mapper s2\r\n",
        "[]\r\n",
        "['def', 'reducer', 'self', 'word', 'counts']\r\n",
        "mapper def\r\n",
        "mapper reducer\r\n",
        "mapper self\r\n",
        "mapper word\r\n",
        "mapper counts\r\n",
        "['yield', 'word', 'sum', 'counts']\r\n",
        "mapper yield\r\n",
        "mapper word\r\n",
        "mapper sum\r\n",
        "mapper counts\r\n",
        "['l_counts', 'c', 'for', 'c', 'in', 'counts', 'extract', 'list', 'from', 'iterator']\r\n",
        "mapper l_counts\r\n",
        "mapper c\r\n",
        "mapper for\r\n",
        "mapper c\r\n",
        "mapper in\r\n",
        "mapper counts\r\n",
        "mapper extract\r\n",
        "mapper list\r\n",
        "mapper from\r\n",
        "mapper iterator\r\n",
        "['S', 'sum', 'l_counts']\r\n",
        "mapper s\r\n",
        "mapper sum\r\n",
        "mapper l_counts\r\n",
        "['S1', '0']\r\n",
        "mapper s1\r\n",
        "mapper 0\r\n",
        "['S2', '0']\r\n",
        "mapper s2\r\n",
        "mapper 0\r\n",
        "['for', 'c', 'in', 'l_counts']\r\n",
        "mapper for\r\n",
        "mapper c\r\n",
        "mapper in\r\n",
        "mapper l_counts\r\n",
        "['S1', 'S1', 'c', '0']\r\n",
        "mapper s1\r\n",
        "mapper s1\r\n",
        "mapper c\r\n",
        "mapper 0\r\n",
        "['S2', 'S2', 'c', '1']\r\n",
        "mapper s2\r\n",
        "mapper s2\r\n",
        "mapper c\r\n",
        "mapper 1\r\n",
        "['logfile', 'write', \"'reducer\", \"'\", 'word', '0', 'word', '1', \"'\", \"'\", \"'\", \"'\", 'join', 'str', 'c', '0', 'for', 'c', 'in', 'l_counts', \"'\", \"'\", 'join', 'str', 'c', '1', 'for', 'c', 'in', 'l_counts', \"'\", \"'\", 'str', 'S1', \"'\", \"'\", 'str', 'S2', \"'\", \"n'\"]\r\n",
        "mapper logfile\r\n",
        "mapper write\r\n",
        "mapper 'reducer\r\n",
        "mapper '\r\n",
        "mapper word\r\n",
        "mapper 0\r\n",
        "mapper word\r\n",
        "mapper 1\r\n",
        "mapper '\r\n",
        "mapper '\r\n",
        "mapper '\r\n",
        "mapper '\r\n",
        "mapper join\r\n",
        "mapper str\r\n",
        "mapper c\r\n",
        "mapper 0\r\n",
        "mapper for\r\n",
        "mapper c\r\n",
        "mapper in\r\n",
        "mapper l_counts\r\n",
        "mapper '\r\n",
        "mapper '\r\n",
        "mapper join\r\n",
        "mapper str\r\n",
        "mapper c\r\n",
        "mapper 1\r\n",
        "mapper for\r\n",
        "mapper c\r\n",
        "mapper in\r\n",
        "mapper l_counts\r\n",
        "mapper '\r\n",
        "mapper '\r\n",
        "mapper str\r\n",
        "mapper s1\r\n",
        "mapper '\r\n",
        "mapper '\r\n",
        "mapper str\r\n",
        "mapper s2\r\n",
        "mapper '\r\n",
        "mapper n'\r\n",
        "['yield', 'word', 'S1', 'S2']\r\n",
        "mapper yield\r\n",
        "mapper word\r\n",
        "mapper s1\r\n",
        "mapper s2\r\n",
        "[]\r\n",
        "['if', '__name__', \"'__main__'\"]\r\n",
        "mapper if\r\n",
        "mapper __name__\r\n",
        "mapper '__main__'\r\n",
        "['MRWordFreqCount', 'run']\r\n",
        "mapper mrwordfreqcount\r\n",
        "mapper run\r\n",
        "combiner '' [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,12,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2]=27,54\r\n",
        "combiner '__main__''__main__' [12]=1,2\r\n",
        "combiner 'combiner'combiner [12]=1,2\r\n",
        "combiner 'log''log' [12]=1,2\r\n",
        "combiner 'mapper'mapper [12]=1,2\r\n",
        "combiner 'reducer'reducer [12]=1,2\r\n",
        "combiner 'w''w' [12]=1,2\r\n",
        "combiner 00 [1,1,1,1,1,1,1,1,1,1,1,12,2,2,2,2,2,2,2,2,2,2,2]=12,24\r\n",
        "combiner 11 [1,1,1,1,1,1,12,2,2,2,2,2,2]=7,14\r\n",
        "combiner 22 [1,1,12,2,2]=3,6\r\n",
        "combiner 20092009 [12]=1,2\r\n",
        "combiner 20102010 [12]=1,2\r\n",
        "combiner __ [12]=1,2\r\n",
        "combiner __name____name__ [12]=1,2\r\n",
        "combiner aa [12]=1,2\r\n",
        "combiner agreedagreed [12]=1,2\r\n",
        "combiner anan [12]=1,2\r\n",
        "combiner andand [12]=1,2\r\n",
        "combiner anyany [12]=1,2\r\n",
        "combiner apacheapache [1,12,2]=2,4\r\n",
        "combiner applicableapplicable [12]=1,2\r\n",
        "combiner asas [12]=1,2\r\n",
        "combiner atat [12]=1,2\r\n",
        "combiner basisbasis [12]=1,2\r\n",
        "combiner binbin [12]=1,2\r\n",
        "combiner byby [12]=1,2\r\n",
        "combiner cc [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,12,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2]=18,36\r\n",
        "combiner classclass [12]=1,2\r\n",
        "combiner classicclassic [12]=1,2\r\n",
        "combiner combinercombiner [12]=1,2\r\n",
        "combiner compilecompile [12]=1,2\r\n",
        "combiner compliancecompliance [12]=1,2\r\n",
        "combiner conditionsconditions [12]=1,2\r\n",
        "combiner copycopy [12]=1,2\r\n",
        "combiner copyrightcopyright [12]=1,2\r\n",
        "combiner countcount [12]=1,2\r\n",
        "combiner countscounts [1,1,1,1,1,12,2,2,2,2,2]=6,12\r\n",
        "combiner defdef [1,1,12,2,2]=3,6\r\n",
        "combiner distributeddistributed [1,12,2]=2,4\r\n",
        "combiner eithereither [12]=1,2\r\n",
        "combiner exceptexcept [12]=1,2\r\n",
        "combiner expressexpress [12]=1,2\r\n",
        "combiner extractextract [1,12,2]=2,4\r\n",
        "combiner filefile [12]=1,2\r\n",
        "combiner findallfindall [1,12,2]=2,4\r\n",
        "combiner forfor [1,1,1,1,1,1,1,1,1,12,2,2,2,2,2,2,2,2,2]=10,20\r\n",
        "combiner frequencyfrequency [12]=1,2\r\n",
        "combiner fromfrom [1,1,1,12,2,2,2]=4,8\r\n",
        "combiner governinggoverning [12]=1,2\r\n",
        "combiner httphttp [12]=1,2\r\n",
        "combiner ifif [12]=1,2\r\n",
        "combiner impliedimplied [12]=1,2\r\n",
        "combiner importimport [1,1,12,2,2]=3,6\r\n",
        "combiner inin [1,1,1,1,1,1,1,1,1,1,12,2,2,2,2,2,2,2,2,2,2]=11,22\r\n",
        "combiner isis [1,12,2]=2,4\r\n",
        "combiner iteratoriterator [1,12,2]=2,4\r\n",
        "combiner jobjob [1,12,2]=2,4\r\n",
        "combiner joinjoin [1,1,1,12,2,2,2]=4,8\r\n",
        "combiner kindkind [12]=1,2\r\n",
        "combiner l_countsl_counts [1,1,1,1,1,1,1,1,1,12,2,2,2,2,2,2,2,2,2]=10,20\r\n",
        "combiner languagelanguage [12]=1,2\r\n",
        "combiner lawlaw [12]=1,2\r\n",
        "combiner licenselicense [1,1,1,1,1,1,1,12,2,2,2,2,2,2,2]=8,16\r\n",
        "combiner licensedlicensed [12]=1,2\r\n",
        "combiner licenseslicenses [12]=1,2\r\n",
        "combiner limitationslimitations [12]=1,2\r\n",
        "combiner lineline [1,1,12,2,2]=3,6\r\n",
        "combiner listlist [1,12,2]=2,4\r\n",
        "combiner logfilelogfile [1,1,1,1,1,12,2,2,2,2,2]=6,12\r\n",
        "combiner lowerlower [1,1,12,2,2]=3,6\r\n",
        "combiner mappermapper [12]=1,2\r\n",
        "combiner mapreducemapreduce [12]=1,2\r\n",
        "combiner maymay [1,12,2]=2,4\r\n",
        "combiner mrjobmrjob [1,1,12,2,2]=3,6\r\n",
        "combiner mrwordfreqcountmrwordfreqcount [1,12,2]=2,4\r\n",
        "combiner n'n' [1,1,1,12,2,2,2]=4,8\r\n",
        "combiner notnot [12]=1,2\r\n",
        "combiner obtainobtain [12]=1,2\r\n",
        "combiner ofof [1,1,12,2,2]=3,6\r\n",
        "combiner onon [12]=1,2\r\n",
        "combiner openopen [12]=1,2\r\n",
        "combiner oror [1,1,12,2,2]=3,6\r\n",
        "combiner orgorg [12]=1,2\r\n",
        "combiner permissionspermissions [12]=1,2\r\n",
        "combiner pythonpython [12]=1,2\r\n",
        "combiner rr [12]=1,2\r\n",
        "combiner rere [1,12,2]=2,4\r\n",
        "combiner reducerreducer [12]=1,2\r\n",
        "combiner requiredrequired [12]=1,2\r\n",
        "combiner runrun [12]=1,2\r\n",
        "combiner ss [1,1,12,2,2]=3,6\r\n",
        "combiner s1s1 [1,1,1,1,1,1,1,1,1,12,2,2,2,2,2,2,2,2,2]=10,20\r\n",
        "combiner s2s2 [1,1,1,1,1,1,1,1,1,12,2,2,2,2,2,2,2,2,2]=10,20\r\n",
        "combiner seesee [12]=1,2\r\n",
        "combiner selfself [1,1,12,2,2]=3,6\r\n",
        "combiner softwaresoftware [12]=1,2\r\n",
        "combiner specificspecific [12]=1,2\r\n",
        "combiner stderrstderr [1,12,2]=2,4\r\n",
        "combiner strstr [1,1,1,1,1,1,1,12,2,2,2,2,2,2,2]=8,16\r\n",
        "combiner sumsum [1,1,1,12,2,2,2]=4,8\r\n",
        "combiner syssys [12]=1,2\r\n",
        "combiner thethe [1,1,1,1,1,1,1,1,1,12,2,2,2,2,2,2,2,2,2]=10,20\r\n",
        "combiner thisthis [12]=1,2\r\n",
        "combiner toto [12]=1,2\r\n",
        "combiner underunder [1,1,12,2,2]=3,6\r\n",
        "combiner unlessunless [12]=1,2\r\n",
        "combiner useuse [12]=1,2\r\n",
        "combiner usrusr [12]=1,2\r\n",
        "combiner versionversion [12]=1,2\r\n",
        "combiner w'w' [12]=1,2\r\n",
        "combiner warrantieswarranties [12]=1,2\r\n",
        "combiner withwith [12]=1,2\r\n",
        "combiner withoutwithout [12]=1,2\r\n",
        "combiner wordword [1,1,1,1,1,1,1,1,1,1,1,1,1,12,2,2,2,2,2,2,2,2,2,2,2,2,2]=14,28\r\n",
        "combiner word_reword_re [1,1,12,2,2]=3,6\r\n",
        "combiner wordswords [12]=1,2\r\n",
        "combiner writewrite [1,1,1,12,2,2,2]=4,8\r\n",
        "combiner writingwriting [12]=1,2\r\n",
        "combiner wwwwww [12]=1,2\r\n",
        "combiner yelpyelp [12]=1,2\r\n",
        "combiner yieldyield [1,1,1,1,12,2,2,2,2]=5,10\r\n",
        "combiner youyou [1,12,2]=2,4\r\n",
        "Counters from step 1:\r\n",
        "  (no counters found)\r\n",
        "writing to /tmp/mr_word_freq_count_test.ubuntu.20140520.191132.787986/step-0-mapper-sorted\r\n",
        "> sort /tmp/mr_word_freq_count_test.ubuntu.20140520.191132.787986/step-0-mapper_part-00000\r\n",
        "writing to /tmp/mr_word_freq_count_test.ubuntu.20140520.191132.787986/step-0-reducer_part-00000\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "reducer '' [2754]=27,54\r\n",
        "reducer '__main__''__main__' [12]=1,2\r\n",
        "reducer 'combiner'combiner [12]=1,2\r\n",
        "reducer 'log''log' [12]=1,2\r\n",
        "reducer 'mapper'mapper [12]=1,2\r\n",
        "reducer 'reducer'reducer [12]=1,2\r\n",
        "reducer 'w''w' [12]=1,2\r\n",
        "reducer 00 [1224]=12,24\r\n",
        "reducer 11 [714]=7,14\r\n",
        "reducer 22 [36]=3,6\r\n",
        "reducer 20092009 [12]=1,2\r\n",
        "reducer 20102010 [12]=1,2\r\n",
        "reducer __ [12]=1,2\r\n",
        "reducer __name____name__ [12]=1,2\r\n",
        "reducer aa [12]=1,2\r\n",
        "reducer agreedagreed [12]=1,2\r\n",
        "reducer anan [12]=1,2\r\n",
        "reducer andand [12]=1,2\r\n",
        "reducer anyany [12]=1,2\r\n",
        "reducer apacheapache [24]=2,4\r\n",
        "reducer applicableapplicable [12]=1,2\r\n",
        "reducer asas [12]=1,2\r\n",
        "reducer atat [12]=1,2\r\n",
        "reducer basisbasis [12]=1,2\r\n",
        "reducer binbin [12]=1,2\r\n",
        "reducer byby [12]=1,2\r\n",
        "reducer cc [1836]=18,36\r\n",
        "reducer classclass [12]=1,2\r\n",
        "reducer classicclassic [12]=1,2\r\n",
        "reducer combinercombiner [12]=1,2\r\n",
        "reducer compilecompile [12]=1,2\r\n",
        "reducer compliancecompliance [12]=1,2\r\n",
        "reducer conditionsconditions [12]=1,2\r\n",
        "reducer copycopy [12]=1,2\r\n",
        "reducer copyrightcopyright [12]=1,2\r\n",
        "reducer countcount [12]=1,2\r\n",
        "reducer countscounts [612]=6,12\r\n",
        "reducer defdef [36]=3,6\r\n",
        "reducer distributeddistributed [24]=2,4\r\n",
        "reducer eithereither [12]=1,2\r\n",
        "reducer exceptexcept [12]=1,2\r\n",
        "reducer expressexpress [12]=1,2\r\n",
        "reducer extractextract [24]=2,4\r\n",
        "reducer filefile [12]=1,2\r\n",
        "reducer findallfindall [24]=2,4\r\n",
        "reducer forfor [1020]=10,20\r\n",
        "reducer frequencyfrequency [12]=1,2\r\n",
        "reducer fromfrom [48]=4,8\r\n",
        "reducer governinggoverning [12]=1,2\r\n",
        "reducer httphttp [12]=1,2\r\n",
        "reducer ifif [12]=1,2\r\n",
        "reducer impliedimplied [12]=1,2\r\n",
        "reducer importimport [36]=3,6\r\n",
        "reducer inin [1122]=11,22\r\n",
        "reducer isis [24]=2,4\r\n",
        "reducer iteratoriterator [24]=2,4\r\n",
        "reducer jobjob [24]=2,4\r\n",
        "reducer joinjoin [48]=4,8\r\n",
        "reducer kindkind [12]=1,2\r\n",
        "reducer l_countsl_counts [1020]=10,20\r\n",
        "reducer languagelanguage [12]=1,2\r\n",
        "reducer lawlaw [12]=1,2\r\n",
        "reducer licenselicense [816]=8,16\r\n",
        "reducer licensedlicensed [12]=1,2\r\n",
        "reducer licenseslicenses [12]=1,2\r\n",
        "reducer limitationslimitations [12]=1,2\r\n",
        "reducer lineline [36]=3,6\r\n",
        "reducer listlist [24]=2,4\r\n",
        "reducer logfilelogfile [612]=6,12\r\n",
        "reducer lowerlower [36]=3,6\r\n",
        "reducer mappermapper [12]=1,2\r\n",
        "reducer mapreducemapreduce [12]=1,2\r\n",
        "reducer maymay [24]=2,4\r\n",
        "reducer mrjobmrjob [36]=3,6\r\n",
        "reducer mrwordfreqcountmrwordfreqcount [24]=2,4\r\n",
        "reducer n'n' [48]=4,8\r\n",
        "reducer notnot [12]=1,2\r\n",
        "reducer obtainobtain [12]=1,2\r\n",
        "reducer ofof [36]=3,6\r\n",
        "reducer onon [12]=1,2\r\n",
        "reducer openopen [12]=1,2\r\n",
        "reducer oror [36]=3,6\r\n",
        "reducer orgorg [12]=1,2\r\n",
        "reducer permissionspermissions [12]=1,2\r\n",
        "reducer pythonpython [12]=1,2\r\n",
        "reducer rr [12]=1,2\r\n",
        "reducer rere [24]=2,4\r\n",
        "reducer reducerreducer [12]=1,2\r\n",
        "reducer requiredrequired [12]=1,2\r\n",
        "reducer runrun [12]=1,2\r\n",
        "reducer ss [36]=3,6\r\n",
        "reducer s1s1 [1020]=10,20\r\n",
        "reducer s2s2 [1020]=10,20\r\n",
        "reducer seesee [12]=1,2\r\n",
        "reducer selfself [36]=3,6\r\n",
        "reducer softwaresoftware [12]=1,2\r\n",
        "reducer specificspecific [12]=1,2\r\n",
        "reducer stderrstderr [24]=2,4\r\n",
        "reducer strstr [816]=8,16\r\n",
        "reducer sumsum [48]=4,8\r\n",
        "reducer syssys [12]=1,2\r\n",
        "reducer thethe [1020]=10,20\r\n",
        "reducer thisthis [12]=1,2\r\n",
        "reducer toto [12]=1,2\r\n",
        "reducer underunder [36]=3,6\r\n",
        "reducer unlessunless [12]=1,2\r\n",
        "reducer useuse [12]=1,2\r\n",
        "reducer usrusr [12]=1,2\r\n",
        "reducer versionversion [12]=1,2\r\n",
        "reducer w'w' [12]=1,2\r\n",
        "reducer warrantieswarranties [12]=1,2\r\n",
        "reducer withwith [12]=1,2\r\n",
        "reducer withoutwithout [12]=1,2\r\n",
        "reducer wordword [1428]=14,28\r\n",
        "reducer word_reword_re [36]=3,6\r\n",
        "reducer wordswords [12]=1,2\r\n",
        "reducer writewrite [48]=4,8\r\n",
        "reducer writingwriting [12]=1,2\r\n",
        "reducer wwwwww [12]=1,2\r\n",
        "reducer yelpyelp [12]=1,2\r\n",
        "reducer yieldyield [510]=5,10\r\n",
        "reducer youyou [24]=2,4\r\n",
        "Counters from step 1:\r\n",
        "  (no counters found)\r\n",
        "Moving /tmp/mr_word_freq_count_test.ubuntu.20140520.191132.787986/step-0-reducer_part-00000 -> /tmp/mr_word_freq_count_test.ubuntu.20140520.191132.787986/output/part-00000\r\n",
        "Streaming final output from /tmp/mr_word_freq_count_test.ubuntu.20140520.191132.787986/output\r\n",
        "removing tmp directory /tmp/mr_word_freq_count_test.ubuntu.20140520.191132.787986\r\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat log"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "cat: log: No such file or directory\r\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat counts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\"'\"\t[27, 54]\r\n",
        "\"'__main__'\"\t[1, 2]\r\n",
        "\"'combiner\"\t[1, 2]\r\n",
        "\"'log'\"\t[1, 2]\r\n",
        "\"'mapper\"\t[1, 2]\r\n",
        "\"'reducer\"\t[1, 2]\r\n",
        "\"'w'\"\t[1, 2]\r\n",
        "\"0\"\t[10, 20]\r\n",
        "\"1\"\t[5, 10]\r\n",
        "\"2\"\t[3, 6]\r\n",
        "\"2009\"\t[1, 2]\r\n",
        "\"2010\"\t[1, 2]\r\n",
        "\"_\"\t[1, 2]\r\n",
        "\"__name__\"\t[1, 2]\r\n",
        "\"a\"\t[1, 2]\r\n",
        "\"agreed\"\t[1, 2]\r\n",
        "\"an\"\t[1, 2]\r\n",
        "\"and\"\t[1, 2]\r\n",
        "\"any\"\t[1, 2]\r\n",
        "\"apache\"\t[2, 4]\r\n",
        "\"applicable\"\t[1, 2]\r\n",
        "\"as\"\t[1, 2]\r\n",
        "\"at\"\t[1, 2]\r\n",
        "\"basis\"\t[1, 2]\r\n",
        "\"bin\"\t[1, 2]\r\n",
        "\"by\"\t[1, 2]\r\n",
        "\"c\"\t[18, 36]\r\n",
        "\"class\"\t[1, 2]\r\n",
        "\"classic\"\t[1, 2]\r\n",
        "\"combiner\"\t[1, 2]\r\n",
        "\"compile\"\t[1, 2]\r\n",
        "\"compliance\"\t[1, 2]\r\n",
        "\"conditions\"\t[1, 2]\r\n",
        "\"copy\"\t[1, 2]\r\n",
        "\"copyright\"\t[1, 2]\r\n",
        "\"count\"\t[1, 2]\r\n",
        "\"counts\"\t[6, 12]\r\n",
        "\"def\"\t[3, 6]\r\n",
        "\"distributed\"\t[2, 4]\r\n",
        "\"either\"\t[1, 2]\r\n",
        "\"except\"\t[1, 2]\r\n",
        "\"express\"\t[1, 2]\r\n",
        "\"extract\"\t[2, 4]\r\n",
        "\"file\"\t[1, 2]\r\n",
        "\"findall\"\t[2, 4]\r\n",
        "\"for\"\t[10, 20]\r\n",
        "\"frequency\"\t[1, 2]\r\n",
        "\"from\"\t[4, 8]\r\n",
        "\"governing\"\t[1, 2]\r\n",
        "\"http\"\t[1, 2]\r\n",
        "\"if\"\t[1, 2]\r\n",
        "\"implied\"\t[1, 2]\r\n",
        "\"import\"\t[3, 6]\r\n",
        "\"in\"\t[11, 22]\r\n",
        "\"is\"\t[2, 4]\r\n",
        "\"iterator\"\t[2, 4]\r\n",
        "\"job\"\t[2, 4]\r\n",
        "\"join\"\t[4, 8]\r\n",
        "\"kind\"\t[1, 2]\r\n",
        "\"l_counts\"\t[10, 20]\r\n",
        "\"language\"\t[1, 2]\r\n",
        "\"law\"\t[1, 2]\r\n",
        "\"license\"\t[8, 16]\r\n",
        "\"licensed\"\t[1, 2]\r\n",
        "\"licenses\"\t[1, 2]\r\n",
        "\"limitations\"\t[1, 2]\r\n",
        "\"line\"\t[3, 6]\r\n",
        "\"list\"\t[2, 4]\r\n",
        "\"logfile\"\t[6, 12]\r\n",
        "\"lower\"\t[2, 4]\r\n",
        "\"mapper\"\t[1, 2]\r\n",
        "\"mapreduce\"\t[1, 2]\r\n",
        "\"may\"\t[2, 4]\r\n",
        "\"mrjob\"\t[3, 6]\r\n",
        "\"mrwordfreqcount\"\t[2, 4]\r\n",
        "\"n'\"\t[4, 8]\r\n",
        "\"not\"\t[1, 2]\r\n",
        "\"obtain\"\t[1, 2]\r\n",
        "\"of\"\t[3, 6]\r\n",
        "\"on\"\t[1, 2]\r\n",
        "\"open\"\t[1, 2]\r\n",
        "\"or\"\t[3, 6]\r\n",
        "\"org\"\t[1, 2]\r\n",
        "\"permissions\"\t[1, 2]\r\n",
        "\"python\"\t[1, 2]\r\n",
        "\"r\"\t[1, 2]\r\n",
        "\"re\"\t[2, 4]\r\n",
        "\"reducer\"\t[1, 2]\r\n",
        "\"required\"\t[1, 2]\r\n",
        "\"run\"\t[1, 2]\r\n",
        "\"s\"\t[3, 6]\r\n",
        "\"s1\"\t[10, 20]\r\n",
        "\"s2\"\t[10, 20]\r\n",
        "\"see\"\t[1, 2]\r\n",
        "\"self\"\t[3, 6]\r\n",
        "\"software\"\t[1, 2]\r\n",
        "\"specific\"\t[1, 2]\r\n",
        "\"stderr\"\t[2, 4]\r\n",
        "\"str\"\t[8, 16]\r\n",
        "\"sum\"\t[4, 8]\r\n",
        "\"sys\"\t[1, 2]\r\n",
        "\"the\"\t[10, 20]\r\n",
        "\"this\"\t[1, 2]\r\n",
        "\"to\"\t[1, 2]\r\n",
        "\"under\"\t[3, 6]\r\n",
        "\"unless\"\t[1, 2]\r\n",
        "\"use\"\t[1, 2]\r\n",
        "\"usr\"\t[1, 2]\r\n",
        "\"version\"\t[1, 2]\r\n",
        "\"w'\"\t[1, 2]\r\n",
        "\"warranties\"\t[1, 2]\r\n",
        "\"with\"\t[1, 2]\r\n",
        "\"without\"\t[1, 2]\r\n",
        "\"word\"\t[11, 22]\r\n",
        "\"word_re\"\t[3, 6]\r\n",
        "\"words\"\t[1, 2]\r\n",
        "\"write\"\t[4, 8]\r\n",
        "\"writing\"\t[1, 2]\r\n",
        "\"www\"\t[1, 2]\r\n",
        "\"yelp\"\t[1, 2]\r\n",
        "\"yield\"\t[5, 10]\r\n",
        "\"you\"\t[2, 4]\r\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "What is the meaning of \"yield\" ?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The keyword __yield__ is somewhat similar to __return__ however, while __return__ terminates the function and returns the result, \n",
      "__yield__, the first time it is encountered, return an object called a __generator__, without executing the function even once. On subsequent calls, the function is executed until one or more __yield__ commands are encountered, these values are returned, and the function halts (but does not terminate) until it is called again.\n",
      "\n",
      "Here is a simple example:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def myrange(start,stop,step):\n",
      "    value=start\n",
      "    while value<=stop:\n",
      "        yield value\n",
      "        value += step\n",
      "print [x for x in myrange(1.0,3.0,0.3)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[1.0, 1.3, 1.6, 1.9000000000000001, 2.2, 2.5, 2.8]\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print myrange(1.0,3.0,0.3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<generator object myrange at 0x3644640>\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gen1=myrange(1.0,3.0,0.3)\n",
      "gen2=myrange(2.0,5.0,0.7)\n",
      "print len(gen1)\n",
      "print 'gen1:',[x for x in gen1]\n",
      "print 'gen1:',[x for x in gen1]  # after the generator terminated, it does not yield any more values.\n",
      "print 'gen2:',[x for x in gen2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "TypeError",
       "evalue": "object of type 'generator' has no len()",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-6-6a7b9e9312f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mgen1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmyrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mgen2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmyrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m'gen1:'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgen1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m'gen1:'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgen1\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# after the generator terminated, it does not yield any more values.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mTypeError\u001b[0m: object of type 'generator' has no len()"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A generator is similar to an array or a list, all of those are __iterable__ objects. However, while list store all of the values in memory and can be read in any order, generators create the values on the fly and can only traversed __once__ and __in order__\n",
      "\n",
      "It is the fact that values are generated on the fly and then discarded which makes generators attractive when processing large amounts of data - only a small amount of intermedite results, the outputs of the mapper which are inputs to the reducer, need to be stored in memory. How much depends on the communication speed between mappers and reducers.\n",
      "\n",
      "It is instructive to see how generators can be cascaded by passing a generator as a parameter to another generator."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def mycumul(values):   # values can be a list or a generator.\n",
      "    s=0\n",
      "    for value in values:\n",
      "        s+=value\n",
      "        yield s"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Here we pass a generator as an input to another generator.\n",
      "gen3=mycumul(myrange(1.0,3.0,0.3))   "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'myrange' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-2-2737b2cce3f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Here we pass a generator as an input to another generator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mgen3\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmycumul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mNameError\u001b[0m: name 'myrange' is not defined"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'gen3:',[x for x in gen3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "gen3: [1.0, 2.3, 3.9, 5.8, 8.0, 10.5, 13.3]\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Different modes of running a mrjob map-reduce job ##\n",
      "\n",
      "Once the mapper, combiner and reducer have been written and tested, you can run the job on different types of infrastructure:\n",
      "\n",
      "1. __inline__ run the job as a single process on the local machine.\n",
      "1. __local__ run the job on the local machine, but using multiple processes to simulate parallel processing.\n",
      "1. __hadoop__ run the job on a hadoop cluster (such as the one we have in SDSC)\n",
      "1. __EMR__ (Elastic Map Reduce) run the job on a hadoop cluster running on the amazon cloud.\n",
      "\n",
      "Below we run the same process we ran at the top using __local__ instead of the default __inline__. Observe that in this case the reducers have some non-trivial work to do even when combiners are used."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Running in local mode"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python mr_word_freq_count.py --runner=local $root_dir/README.rst > counts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "using configs in /home/ubuntu/.mrjob.conf\r\n",
        "creating tmp directory /tmp/mr_word_freq_count.ubuntu.20140518.193105.385047\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "writing to /tmp/mr_word_freq_count.ubuntu.20140518.193105.385047/step-0-mapper_part-00000\r\n",
        "> /home/ubuntu/anaconda/bin/python mr_word_freq_count.py --step-num=0 --mapper /tmp/mr_word_freq_count.ubuntu.20140518.193105.385047/input_part-00000 | sort | /home/ubuntu/anaconda/bin/python mr_word_freq_count.py --step-num=0 --combiner > /tmp/mr_word_freq_count.ubuntu.20140518.193105.385047/step-0-mapper_part-00000\r\n",
        "writing to /tmp/mr_word_freq_count.ubuntu.20140518.193105.385047/step-0-mapper_part-00001\r\n",
        "> /home/ubuntu/anaconda/bin/python mr_word_freq_count.py --step-num=0 --mapper /tmp/mr_word_freq_count.ubuntu.20140518.193105.385047/input_part-00001 | sort | /home/ubuntu/anaconda/bin/python mr_word_freq_count.py --step-num=0 --combiner > /tmp/mr_word_freq_count.ubuntu.20140518.193105.385047/step-0-mapper_part-00001\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "STDERR: mapper usr\r\n",
        "STDERR: mapper bin\r\n",
        "STDERR: mapper python\r\n",
        "STDERR: mapper copyright\r\n",
        "STDERR: mapper 2009\r\n",
        "STDERR: mapper 2010\r\n",
        "STDERR: mapper yelp\r\n",
        "STDERR: mapper licensed\r\n",
        "STDERR: mapper under\r\n",
        "STDERR: mapper the\r\n",
        "STDERR: mapper apache\r\n",
        "STDERR: mapper license\r\n",
        "STDERR: mapper version\r\n",
        "STDERR: mapper 2\r\n",
        "STDERR: mapper 0\r\n",
        "STDERR: mapper the\r\n",
        "STDERR: mapper license\r\n",
        "STDERR: mapper you\r\n",
        "STDERR: mapper may\r\n",
        "STDERR: mapper not\r\n",
        "STDERR: mapper use\r\n",
        "STDERR: mapper this\r\n",
        "STDERR: mapper file\r\n",
        "STDERR: mapper except\r\n",
        "STDERR: mapper in\r\n",
        "STDERR: mapper compliance\r\n",
        "STDERR: mapper with\r\n",
        "STDERR: mapper the\r\n",
        "STDERR: mapper license\r\n",
        "STDERR: mapper you\r\n",
        "STDERR: mapper may\r\n",
        "STDERR: mapper obtain\r\n",
        "STDERR: mapper a\r\n",
        "STDERR: mapper copy\r\n",
        "STDERR: mapper of\r\n",
        "STDERR: mapper the\r\n",
        "STDERR: mapper license\r\n",
        "STDERR: mapper at\r\n",
        "STDERR: mapper http\r\n",
        "STDERR: mapper www\r\n",
        "STDERR: mapper apache\r\n",
        "STDERR: mapper org\r\n",
        "STDERR: mapper licenses\r\n",
        "STDERR: mapper license\r\n",
        "STDERR: mapper 2\r\n",
        "STDERR: mapper 0\r\n",
        "STDERR: mapper unless\r\n",
        "STDERR: mapper required\r\n",
        "STDERR: mapper by\r\n",
        "STDERR: mapper applicable\r\n",
        "STDERR: mapper law\r\n",
        "STDERR: mapper or\r\n",
        "STDERR: mapper agreed\r\n",
        "STDERR: mapper to\r\n",
        "STDERR: mapper in\r\n",
        "STDERR: mapper writing\r\n",
        "STDERR: mapper software\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "STDERR: combiner 0 [1,1]=2\r\n",
        "STDERR: combiner 2009 [1]=1\r\n",
        "STDERR: combiner 2010 [1]=1\r\n",
        "STDERR: combiner 2 [1,1]=2\r\n",
        "STDERR: combiner a [1]=1\r\n",
        "STDERR: combiner agreed [1]=1\r\n",
        "STDERR: combiner apache [1,1]=2\r\n",
        "STDERR: combiner applicable [1]=1\r\n",
        "STDERR: combiner at [1]=1\r\n",
        "STDERR: combiner bin [1]=1\r\n",
        "STDERR: combiner by [1]=1\r\n",
        "STDERR: combiner compliance [1]=1\r\n",
        "STDERR: combiner copy [1]=1\r\n",
        "STDERR: combiner copyright [1]=1\r\n",
        "STDERR: combiner except [1]=1\r\n",
        "STDERR: combiner file [1]=1\r\n",
        "STDERR: combiner http [1]=1\r\n",
        "STDERR: combiner in [1,1]=2\r\n",
        "STDERR: combiner law [1]=1\r\n",
        "STDERR: combiner license [1,1,1,1,1]=5\r\n",
        "STDERR: combiner licensed [1]=1\r\n",
        "STDERR: combiner licenses [1]=1\r\n",
        "STDERR: combiner may [1,1]=2\r\n",
        "STDERR: combiner not [1]=1\r\n",
        "STDERR: combiner obtain [1]=1\r\n",
        "STDERR: combiner of [1]=1\r\n",
        "STDERR: combiner or [1]=1\r\n",
        "STDERR: combiner org [1]=1\r\n",
        "STDERR: combiner python [1]=1\r\n",
        "STDERR: combiner required [1]=1\r\n",
        "STDERR: combiner software [1]=1\r\n",
        "STDERR: combiner the [1,1,1,1]=4\r\n",
        "STDERR: combiner this [1]=1\r\n",
        "STDERR: combiner to [1]=1\r\n",
        "STDERR: combiner under [1]=1\r\n",
        "STDERR: combiner unless [1]=1\r\n",
        "STDERR: combiner use [1]=1\r\n",
        "STDERR: combiner usr [1]=1\r\n",
        "STDERR: combiner version [1]=1\r\n",
        "STDERR: combiner with [1]=1\r\n",
        "STDERR: combiner writing [1]=1\r\n",
        "STDERR: combiner www [1]=1\r\n",
        "STDERR: combiner yelp [1]=1\r\n",
        "STDERR: combiner you [1,1]=2\r\n",
        "STDERR: mapper distributed\r\n",
        "STDERR: mapper under\r\n",
        "STDERR: mapper the\r\n",
        "STDERR: mapper license\r\n",
        "STDERR: mapper is\r\n",
        "STDERR: mapper distributed\r\n",
        "STDERR: mapper on\r\n",
        "STDERR: mapper an\r\n",
        "STDERR: mapper as\r\n",
        "STDERR: mapper is\r\n",
        "STDERR: mapper basis\r\n",
        "STDERR: mapper without\r\n",
        "STDERR: mapper warranties\r\n",
        "STDERR: mapper or\r\n",
        "STDERR: mapper conditions\r\n",
        "STDERR: mapper of\r\n",
        "STDERR: mapper any\r\n",
        "STDERR: mapper kind\r\n",
        "STDERR: mapper either\r\n",
        "STDERR: mapper express\r\n",
        "STDERR: mapper or\r\n",
        "STDERR: mapper implied\r\n",
        "STDERR: mapper see\r\n",
        "STDERR: mapper the\r\n",
        "STDERR: mapper license\r\n",
        "STDERR: mapper for\r\n",
        "STDERR: mapper the\r\n",
        "STDERR: mapper specific\r\n",
        "STDERR: mapper language\r\n",
        "STDERR: mapper governing\r\n",
        "STDERR: mapper permissions\r\n",
        "STDERR: mapper and\r\n",
        "STDERR: mapper limitations\r\n",
        "STDERR: mapper under\r\n",
        "STDERR: mapper the\r\n",
        "STDERR: mapper license\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "STDERR: combiner an [1]=1\r\n",
        "STDERR: combiner and [1]=1\r\n",
        "STDERR: combiner any [1]=1\r\n",
        "STDERR: combiner as [1]=1\r\n",
        "STDERR: combiner basis [1]=1\r\n",
        "STDERR: combiner conditions [1]=1\r\n",
        "STDERR: combiner distributed [1,1]=2\r\n",
        "STDERR: combiner either [1]=1\r\n",
        "STDERR: combiner express [1]=1\r\n",
        "STDERR: combiner for [1]=1\r\n",
        "STDERR: combiner governing [1]=1\r\n",
        "STDERR: combiner implied [1]=1\r\n",
        "STDERR: combiner is [1,1]=2\r\n",
        "STDERR: combiner kind [1]=1\r\n",
        "STDERR: combiner language [1]=1\r\n",
        "STDERR: combiner license [1,1,1]=3\r\n",
        "STDERR: combiner limitations [1]=1\r\n",
        "STDERR: combiner of [1]=1\r\n",
        "STDERR: combiner on [1]=1\r\n",
        "STDERR: combiner or [1,1]=2\r\n",
        "STDERR: combiner permissions [1]=1\r\n",
        "STDERR: combiner see [1]=1\r\n",
        "STDERR: combiner specific [1]=1\r\n",
        "STDERR: combiner the [1,1,1,1]=4\r\n",
        "STDERR: combiner under [1,1]=2\r\n",
        "STDERR: combiner warranties [1]=1\r\n",
        "STDERR: combiner without [1]=1\r\n",
        "Counters from step 1:\r\n",
        "  (no counters found)\r\n",
        "writing to /tmp/mr_word_freq_count.ubuntu.20140518.193105.385047/step-0-mapper-sorted\r\n",
        "> sort /tmp/mr_word_freq_count.ubuntu.20140518.193105.385047/step-0-mapper_part-00000 /tmp/mr_word_freq_count.ubuntu.20140518.193105.385047/step-0-mapper_part-00001\r\n",
        "writing to /tmp/mr_word_freq_count.ubuntu.20140518.193105.385047/step-0-reducer_part-00000\r\n",
        "> /home/ubuntu/anaconda/bin/python mr_word_freq_count.py --step-num=0 --reducer /tmp/mr_word_freq_count.ubuntu.20140518.193105.385047/input_part-00000 > /tmp/mr_word_freq_count.ubuntu.20140518.193105.385047/step-0-reducer_part-00000\r\n",
        "writing to /tmp/mr_word_freq_count.ubuntu.20140518.193105.385047/step-0-reducer_part-00001\r\n",
        "> /home/ubuntu/anaconda/bin/python mr_word_freq_count.py --step-num=0 --reducer /tmp/mr_word_freq_count.ubuntu.20140518.193105.385047/input_part-00001 > /tmp/mr_word_freq_count.ubuntu.20140518.193105.385047/step-0-reducer_part-00001\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "STDERR: reducer 0 [2]=2\r\n",
        "STDERR: reducer 2 [2]=2\r\n",
        "STDERR: reducer 2009 [1]=1\r\n",
        "STDERR: reducer 2010 [1]=1\r\n",
        "STDERR: reducer a [1]=1\r\n",
        "STDERR: reducer agreed [1]=1\r\n",
        "STDERR: reducer an [1]=1\r\n",
        "STDERR: reducer and [1]=1\r\n",
        "STDERR: reducer any [1]=1\r\n",
        "STDERR: reducer apache [2]=2\r\n",
        "STDERR: reducer applicable [1]=1\r\n",
        "STDERR: reducer as [1]=1\r\n",
        "STDERR: reducer at [1]=1\r\n",
        "STDERR: reducer basis [1]=1\r\n",
        "STDERR: reducer bin [1]=1\r\n",
        "STDERR: reducer by [1]=1\r\n",
        "STDERR: reducer compliance [1]=1\r\n",
        "STDERR: reducer conditions [1]=1\r\n",
        "STDERR: reducer copy [1]=1\r\n",
        "STDERR: reducer copyright [1]=1\r\n",
        "STDERR: reducer distributed [2]=2\r\n",
        "STDERR: reducer either [1]=1\r\n",
        "STDERR: reducer except [1]=1\r\n",
        "STDERR: reducer express [1]=1\r\n",
        "STDERR: reducer file [1]=1\r\n",
        "STDERR: reducer for [1]=1\r\n",
        "STDERR: reducer governing [1]=1\r\n",
        "STDERR: reducer http [1]=1\r\n",
        "STDERR: reducer implied [1]=1\r\n",
        "STDERR: reducer in [2]=2\r\n",
        "STDERR: reducer is [2]=2\r\n",
        "STDERR: reducer kind [1]=1\r\n",
        "STDERR: reducer language [1]=1\r\n",
        "STDERR: reducer law [1]=1\r\n",
        "STDERR: reducer license [3,5]=8\r\n",
        "STDERR: reducer licensed [1]=1\r\n",
        "STDERR: reducer licenses [1]=1\r\n",
        "STDERR: reducer limitations [1]=1\r\n",
        "STDERR: reducer may [2]=2\r\n",
        "STDERR: reducer not [1]=1\r\n",
        "STDERR: reducer obtain [1]=1\r\n",
        "STDERR: reducer of [1,1]=2\r\n",
        "STDERR: reducer on [1]=1\r\n",
        "STDERR: reducer or [1,2]=3\r\n",
        "STDERR: reducer org [1]=1\r\n",
        "STDERR: reducer permissions [1]=1\r\n",
        "STDERR: reducer python [1]=1\r\n",
        "STDERR: reducer required [1]=1\r\n",
        "STDERR: reducer see [1]=1\r\n",
        "STDERR: reducer software [1]=1\r\n",
        "STDERR: reducer specific [1]=1\r\n",
        "STDERR: reducer the [4,4]=8\r\n",
        "STDERR: reducer this [1]=1\r\n",
        "STDERR: reducer to [1]=1\r\n",
        "STDERR: reducer under [1,2]=3\r\n",
        "STDERR: reducer unless [1]=1\r\n",
        "STDERR: reducer use [1]=1\r\n",
        "STDERR: reducer usr [1]=1\r\n",
        "STDERR: reducer version [1]=1\r\n",
        "STDERR: reducer warranties [1]=1\r\n",
        "STDERR: reducer with [1]=1\r\n",
        "STDERR: reducer without [1]=1\r\n",
        "STDERR: reducer writing [1]=1\r\n",
        "STDERR: reducer www [1]=1\r\n",
        "STDERR: reducer yelp [1]=1\r\n",
        "STDERR: reducer you [2]=2\r\n",
        "Counters from step 1:\r\n",
        "  (no counters found)\r\n",
        "Moving /tmp/mr_word_freq_count.ubuntu.20140518.193105.385047/step-0-reducer_part-00000 -> /tmp/mr_word_freq_count.ubuntu.20140518.193105.385047/output/part-00000\r\n",
        "Moving /tmp/mr_word_freq_count.ubuntu.20140518.193105.385047/step-0-reducer_part-00001 -> /tmp/mr_word_freq_count.ubuntu.20140518.193105.385047/output/part-00001\r\n",
        "Streaming final output from /tmp/mr_word_freq_count.ubuntu.20140518.193105.385047/output\r\n",
        "removing tmp directory /tmp/mr_word_freq_count.ubuntu.20140518.193105.385047\r\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Running in EMR mode on a dedicated job flow"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python mr_word_freq_count.py -r emr $root_dir/README.rst > counts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "using configs in /home/ubuntu/.mrjob.conf\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "creating tmp directory /tmp/mr_word_freq_count.ubuntu.20140518.193143.370028\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "writing master bootstrap script to /tmp/mr_word_freq_count.ubuntu.20140518.193143.370028/b.py\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Copying non-input files into s3://ye.bucket/weather/scratch/mr_word_freq_count.ubuntu.20140518.193143.370028/files/\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Waiting 5.0s for S3 eventual consistency\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Creating Elastic MapReduce job flow\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job flow created with ID: j-VQOMX5DIN001\r\n",
        "Created new job flow j-VQOMX5DIN001\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 30.1s ago, status STARTING: Provisioning Amazon EC2 capacity\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 60.2s ago, status STARTING: Provisioning Amazon EC2 capacity\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 90.4s ago, status STARTING: Provisioning Amazon EC2 capacity\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 120.5s ago, status STARTING: Provisioning Amazon EC2 capacity\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 150.6s ago, status BOOTSTRAPPING: Running bootstrap actions\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 180.7s ago, status BOOTSTRAPPING: Running bootstrap actions\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 210.8s ago, status BOOTSTRAPPING: Running bootstrap actions\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 240.9s ago, status BOOTSTRAPPING: Running bootstrap actions\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 271.1s ago, status BOOTSTRAPPING: Running bootstrap actions\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 301.2s ago, status RUNNING: Running step (mr_word_freq_count.ubuntu.20140518.193143.370028: Step 1 of 1)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 331.3s ago, status RUNNING: Running step (mr_word_freq_count.ubuntu.20140518.193143.370028: Step 1 of 1)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 361.5s ago, status RUNNING: Running step (mr_word_freq_count.ubuntu.20140518.193143.370028: Step 1 of 1)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 391.6s ago, status RUNNING: Running step (mr_word_freq_count.ubuntu.20140518.193143.370028: Step 1 of 1)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 421.7s ago, status RUNNING: Running step (mr_word_freq_count.ubuntu.20140518.193143.370028: Step 1 of 1)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job completed.\r\n",
        "Running time was 117.0s (not counting time spent waiting for the EC2 instances)\r\n",
        "ec2_key_pair_file not specified, going to S3\r\n",
        "Fetching counters from S3...\r\n",
        "Waiting 5.0s for S3 eventual consistency\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Counters from step 1:\r\n",
        "  File Input Format Counters :\r\n",
        "    Bytes Read: 1475\r\n",
        "  File Output Format Counters :\r\n",
        "    Bytes Written: 664\r\n",
        "  FileSystemCounters:\r\n",
        "    FILE_BYTES_READ: 643\r\n",
        "    FILE_BYTES_WRITTEN: 138750\r\n",
        "    HDFS_BYTES_READ: 596\r\n",
        "    S3_BYTES_READ: 1475\r\n",
        "    S3_BYTES_WRITTEN: 664\r\n",
        "  Job Counters :\r\n",
        "    Launched map tasks: 4\r\n",
        "    Launched reduce tasks: 1\r\n",
        "    Rack-local map tasks: 4\r\n",
        "    SLOTS_MILLIS_MAPS: 85662\r\n",
        "    SLOTS_MILLIS_REDUCES: 39014\r\n",
        "    Total time spent by all maps waiting after reserving slots (ms): 0\r\n",
        "    Total time spent by all reduces waiting after reserving slots (ms): 0\r\n",
        "  Map-Reduce Framework:\r\n",
        "    CPU time spent (ms): 6440\r\n",
        "    Combine input records: 93\r\n",
        "    Combine output records: 82\r\n",
        "    Map input bytes: 587\r\n",
        "    Map input records: 14\r\n",
        "    Map output bytes: 914\r\n",
        "    Map output materialized bytes: 868\r\n",
        "    Map output records: 93\r\n",
        "    Physical memory (bytes) snapshot: 881901568\r\n",
        "    Reduce input groups: 66\r\n",
        "    Reduce input records: 82\r\n",
        "    Reduce output records: 66\r\n",
        "    Reduce shuffle bytes: 868\r\n",
        "    SPLIT_RAW_BYTES: 596\r\n",
        "    Spilled Records: 164\r\n",
        "    Total committed heap usage (bytes): 606765056\r\n",
        "    Virtual memory (bytes) snapshot: 3261452288\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Streaming final output from s3://ye.bucket/weather/scratch/mr_word_freq_count.ubuntu.20140518.193143.370028/output/\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "removing tmp directory /tmp/mr_word_freq_count.ubuntu.20140518.193143.370028\r\n",
        "Removing all files in s3://ye.bucket/weather/scratch/mr_word_freq_count.ubuntu.20140518.193143.370028/\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Removing all files in s3://ye.bucket/weather/logs/j-VQOMX5DIN001/\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Terminating job flow: j-VQOMX5DIN001\r\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Running in EMR mode on existing job flow (hadoop cluster)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "job_flow_id='j-3MMGSXIO3FQR3'\n",
      "!python mr_word_freq_count.py -r emr --emr-job-flow-id=j-3MMGSXIO3FQR3  $root_dir/README.rst > counts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "using configs in /Users/yoavfreund/.mrjob.conf\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "using existing scratch bucket mrjob-71c4e33417a2cde8\r\n",
        "using s3://mrjob-71c4e33417a2cde8/tmp/ as our scratch dir on S3\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "creating tmp directory /var/folders/80/c2kfvdvx5cx570r4vlzqgb840000gq/T/mr_word_freq_count.yoavfreund.20140507.195205.656489\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Copying non-input files into s3://mrjob-71c4e33417a2cde8/tmp/mr_word_freq_count.yoavfreund.20140507.195205.656489/files/\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Adding our job to existing job flow j-3MMGSXIO3FQR3\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 30.4s ago, status RUNNING: Running step (mr_word_freq_count.yoavfreund.20140507.195205.656489: Step 1 of 1)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 60.9s ago, status RUNNING: Running step (mr_word_freq_count.yoavfreund.20140507.195205.656489: Step 1 of 1)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 91.4s ago, status RUNNING: Running step (mr_word_freq_count.yoavfreund.20140507.195205.656489: Step 1 of 1)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job on job flow j-3MMGSXIO3FQR3 failed with status WAITING: Waiting after step failed\r\n",
        "Logs are in s3://yoav.hadoop/j-3MMGSXIO3FQR3/\r\n",
        "ec2_key_pair_file not specified, going to S3\r\n",
        "Scanning S3 logs for probable cause of failure\r\n",
        "Waiting 5.0s for S3 eventual consistency\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Attempting to terminate job...\r\n",
        "Traceback (most recent call last):\r\n",
        "  File \"mr_word_freq_count.py\", line 48, in <module>\r\n",
        "    MRWordFreqCount.run()\r\n",
        "  File \"//anaconda/lib/python2.7/site-packages/mrjob/job.py\", line 494, in run\r\n",
        "    mr_job.execute()\r\n",
        "  File \"//anaconda/lib/python2.7/site-packages/mrjob/job.py\", line 512, in execute\r\n",
        "    super(MRJob, self).execute()\r\n",
        "  File \"//anaconda/lib/python2.7/site-packages/mrjob/launch.py\", line 147, in execute\r\n",
        "    self.run_job()\r\n",
        "  File \"//anaconda/lib/python2.7/site-packages/mrjob/launch.py\", line 213, in run_job\r\n",
        "    self.stdout.flush()\r\n",
        "  File \"//anaconda/lib/python2.7/site-packages/mrjob/runner.py\", line 614, in __exit__\r\n",
        "    self.cleanup()\r\n",
        "  File \"//anaconda/lib/python2.7/site-packages/mrjob/emr.py\", line 1010, in cleanup\r\n",
        "    super(EMRJobRunner, self).cleanup(mode=mode)\r\n",
        "  File \"//anaconda/lib/python2.7/site-packages/mrjob/runner.py\", line 560, in cleanup\r\n",
        "    self._cleanup_job()\r\n",
        "  File \"//anaconda/lib/python2.7/site-packages/mrjob/emr.py\", line 1084, in _cleanup_job\r\n",
        "    self._opts['ec2_key_pair_file'])\r\n",
        "  File \"//anaconda/lib/python2.7/site-packages/mrjob/ssh.py\", line 200, in ssh_terminate_single_job\r\n",
        "    ssh_bin, address, ec2_key_pair_file, ['hadoop', 'job', '-list']))\r\n",
        "  File \"//anaconda/lib/python2.7/site-packages/mrjob/ssh.py\", line 82, in ssh_run\r\n",
        "    p = Popen(args, stdout=PIPE, stderr=PIPE, stdin=PIPE)\r\n",
        "  File \"//anaconda/lib/python2.7/subprocess.py\", line 709, in __init__\r\n",
        "    errread, errwrite)\r\n",
        "  File \"//anaconda/lib/python2.7/subprocess.py\", line 1326, in _execute_child\r\n",
        "    raise child_exception\r\n",
        "TypeError: execv() arg 2 must contain only strings\r\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ls mrjob/examples/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "__init__.py             mr_jar_step_example.py  \u001b[34mmr_postfix_bounce\u001b[m\u001b[m       \u001b[31mmr_word_freq_count.py\u001b[m\u001b[m\r\n",
        "\u001b[34mbash_wrap\u001b[m\u001b[m               mr_log_sampler.py       mr_text_classifier.py   py3k_word_freq_count.py\r\n",
        "\u001b[34mcontrib\u001b[m\u001b[m                 \u001b[31mmr_most_used_word.py\u001b[m\u001b[m    \u001b[34mmr_travelling_salesman\u001b[m\u001b[m\r\n",
        "mr_cmd.py               mr_next_word_stats.py   mr_wc.py\r\n",
        "mr_grep.py              mr_page_rank.py         \u001b[31mmr_wc.rb\u001b[m\u001b[m\r\n"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load $root_dir/examples/mr_travelling_salesman/README.rst"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### HW ###\n",
      "1) Look around in the examples directory\n",
      "2) Write a map-reduce job that computes the PCA of a large set of vectors (use as input the max_temp profiles in \n",
      "   /home/ubuntu/data/weather/SAMPLE_TMAX.csv)\n",
      "\n",
      "**Hint:** One map-reduce job is enough. You might think that you first need to compute the means $\\mu_i=E(X_i)$ and then, in a second path, compute\n",
      "$$cov(X_i,X_j) = E((X_i-\\mu_i)(X_j-\\mu_j))$$\n",
      "However, recall the formula \n",
      "$$ var(X) \\doteq E((X-\\mu)^2) = E(X^2) - E(X)^2 $$\n",
      "This formula can be generalized to the $cov$ matrix."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!wc /home/ubuntu/data/weather/SAMPLE_TMAX.csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   20000    20000 26114979 /home/ubuntu/data/weather/SAMPLE_TMAX.csv\r\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}